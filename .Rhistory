View(bestoutcome)
result<<-(best("NY", "pneumonia"))
result<<-best("NY", "pneumonia")
best("NY", "pneumonia")
best <- function(State,outcome) {
## Read outcome data
outcomes <- c("heart attack"=11, "heart failure"=17, "pneumonia"=23)
col_index<<-(outcomes[outcome])
filein<<-("f:/coursera/assignments/Week4/outcome-of-care-measures.csv")
datain<<-read.csv(filein, na.strings = "Not Available",stringsAsFactors=FALSE )
State<<-"AL"
## Check that state and outcome are valid
df1<<-datain[datain$State==State & !is.na(datain[,col_index]),c(2,7,col_index)]
## Return hospital name in that state with lowest 30-day death rate
bestoutcome<<-df1[df1[,3]==min(df1[,3]),1:3]
colnames(bestoutcome) <<- c("Hospital","State","Outcome")
}
#best("AL","heart attack")
#"heart attack(11)", "heart failure(17)", "pneumonia(23)"
best("NY", "pneumonia")
View(bestoutcome)
best("AK", "pneumonia")
View(bestoutcome)
rankhospital <- function(State,outcome,num="best") {
outcomes <<- c("heart attack"=11, "heart failure"=17, "pneumonia"=23)
col_index<<-(outcomes[outcome])
## Read data
filein<-("f:/coursera/assignments/Week4/outcome-of-care-measures.csv")
datain<<-read.csv(filein, na.strings = "Not Available",stringsAsFactors=FALSE )
## Validate data Entry (state & outcome)
if (!State %in% datain$State & !outcome %in% names(outcomes)) {
stop("invalid state and outcome")}
if (!State %in% datain$State) {
stop("invalid state")}
if (!outcome %in% names(outcomes)) {
stop("invalid outcome")}
## Check that state and outcome are valid
statedf<<-datain[datain$State==State & !is.na(datain[,col_index]),c(2,7,col_index)]
colnames(statedf)<-c("Hospital","State","Rate")
rankdf<<-statedf[order(statedf$Rate,statedf$Hospital),]
rankdf$Rank<<- rank(rankdf$Rate, ties.method= "first")
## Find hospital with specified ranking.
nums<<-c("best"=1,worst=nrow(rankdf))
if (!is.numeric(num)) {
num_index<-(nums[num]) }
else {
num_index<-num}
result<<-rankdf[rankdf$Rank==num_index,]
}
rankhospital("NC", "heart attack", "worst")
View(result)
rankhospital("WA", "heart attack", 7)
View(bestoutcome)
rankhospital <- function(State,outcome,num="best") {
outcomes <<- c("heart attack"=11, "heart failure"=17, "pneumonia"=23)
col_index<<-(outcomes[outcome])
## Read data
filein<-("f:/coursera/assignments/Week4/outcome-of-care-measures.csv")
datain<<-read.csv(filein, na.strings = "Not Available",stringsAsFactors=FALSE )
## Validate data Entry (state & outcome)
if (!State %in% datain$State & !outcome %in% names(outcomes)) {
stop("invalid state and outcome")}
if (!State %in% datain$State) {
stop("invalid state")}
if (!outcome %in% names(outcomes)) {
stop("invalid outcome")}
## Check that state and outcome are valid
statedf<<-datain[datain$State==State & !is.na(datain[,col_index]),c(2,7,col_index)]
colnames(statedf)<-c("Hospital","State","Rate")
rankdf<<-statedf[order(statedf$Rate,statedf$Hospital),]
rankdf$Rank<<- rank(rankdf$Rate, ties.method= "first")
## Find hospital with specified ranking.
nums<<-c("best"=1,worst=nrow(rankdf))
if (!is.numeric(num)) {
num_index<-(nums[num]) }
else {
num_index<-num}
result<<-rankdf[rankdf$Rank==num_index,]
}
rankhospital("WA", "heart attack", 7)
View(result)
rankhospital("TX", "pneumonia", 10)
View(result)
rankhospital("NY", "heart attack", 7)
View(result)
r <- rankall("heart attack", 4)
as.character(subset(r, state == "HI")$hospital)
r <<- rankall("heart attack", 4)
as.character(subset(r, state == "HI")$hospital)
rankall <- function(outcome, num = "best") {
outcomes <<- c("heart attack"=11, "heart failure"=17, "pneumonia"=23)
col_index<<-(outcomes[outcome])
## Read outcome data
filein<-("f:/coursera/assignments/Week4/outcome-of-care-measures.csv")
datain<<-read.csv(filein, na.strings = "Not Available",stringsAsFactors=FALSE,header=TRUE )
## Check that state and outcome are valid
if (!outcome %in% names(outcomes)) {
stop("invalid outcome")}
datain0<<-(datain[c(2,7,col_index)])
datain<<-datain0[complete.cases(datain0),]
colnames(datain)<-c("hospital","state","rate")
states<<-(split(datain,datain$state))
states[c(1,3)]
#(lapply(states$rate, sum))
orderdf<<-(lapply(states, function(x) {
x[order(x[,3],x[,1]),]
}))
rankdf<<-lapply(orderdf, function(x) { x$rank <- rank(x$rate,ties.method = "first" ); x })
if (!is.numeric(num)) {
num_index<-(nums[num]) }
print(num)
resultdf<<-sapply(rankdf, function(x,num_index) {
nums<<-c("best"=1,worst=nrow(x))
if (!is.numeric(num)) {
num_index<-(nums[num]) }
else {
num_index<-num}
x[x[,4]==num_index,c(1,2)]
},num_index)
resultdf1<<-t(resultdf)
resultdf1<<-resultdf1[resultdf1[,1]!= "character(0)",]
## For each state, find the hospital of the given rank
## Return a data frame with the hospital names and the
## (abbreviated) state name
}
r <<- rankall("heart attack", 4)
as.character(subset(r, state == "HI")$hospital)
View(r)
View(r)
View(r)
r <- rankall("pneumonia", "worst")
as.character(subset(r, r$state == "NJ")$hospital)
View(r)
View(r)
r <- rankall("heart failure", 10)
result<<-as.character(subset(r, r$state == "NV")$hospital)
View(r)
subset(r, r$state == "NV")$hospital
r[r$state=="NV"]
r[r$state=="NV",]
r[r$state=="NE",]
View(r)
str(r)
swirl()
library(swirl)
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
1
swirl()
read.csv(path2csv,stringsAsFactors=FALSE)
mydf<-read.csv(path2csv,stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tbl(mydf)
cran<-tbl_df(mydf)
rm(mydf)
rm("mydf")
cran
?select
select(cran, ip_id,package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran,-time)
select(cran, -X:size)
select(cran, -(X:size))
-5:20
-(5:20)
select(cran,-(X:size))
filer(cran,package=="swirl")
filter(cran,package=="swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size>"100500" & r_os == "linux-gnu")
filter(cran, size> 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.version(r_os))
filter(cran, !is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(crans2,package,ip_id)
arrange(cran2,package,ip_id)
arrange(cran2,country, desc(r_version), ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20,size_gb = size_mb / 2^10)
mutate(cran3, correct_size=1000)
mutate(cran3, correct_size=size+1000)
summarize(cran, avg_bytes = mean(size))
dir<-("f:/coursera/cleanexam/")
filename<-("communities.csv")
path<-c(dir,filename)
path
dir<-("f:/coursera/cleanexam/")
filename<-("communities.csv")
path<-c(dir,filename,quote=no)
dir<-("f:/coursera/cleanexam/")
filename<-("communities.csv")
path<-c(dir,filename,sep="")
path
?c()
?c
dir<-("f:/coursera/cleanexam/")
filename<-("communities.csv")
path<-c(dir,filename,"/",sep="")
path
dir<-"f:/coursera/cleanexam/"
filename<-"communities.csv"
path<-c(dir,filename,"/",sep="")
path
dir<-"f:/coursera/cleanexam/"
filename<-"communities.csv"
path<-paste(dir,filename,"/",sep="")
path
dir<-"f:/coursera/cleanexam/"
filename<-"communities.csv"
path<-paste(dir,filename,"/",sep="")
dir<-"f:/coursera/cleanexam/"
filename<-"communities.csv"
path<-paste(dir,filename,"/",sep="")
communities<<-read.csv(path)
dir<-"f:/coursera/cleanexam/"
filename<-"communities.csv"
path<-paste(dir,filename,"/",sep="")
read.csv(path)
read.csv(path)
dir<-"f:/coursera/cleanexam/"
filename<-"communities.csv"
path<-paste(dir,filename,,sep="")
communities<<-read.csv(path)
dir<-"f:/coursera/cleanexam/"
filename<-"communities.csv"
path<-paste(dir,filename,sep="")
communities<<-read.csv(path)
View(communities)
View(communities)
communities<-tbl_df(communities)
View(communities)
commnunities
communities
View(communities)
value<<-select(communities)
value<<-select(communities,val)
value<<-select(communities,VAL)
View(value)
filter(communities,VAL==24)
valsum<-filter(communities,VAL==24)
valsum
valsum
valsum<-filter(value,VAL==24)
valsum
FES<<-select(communities,FES)
FES
swirl()
submit()
pacl_sum
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(pack_sum,unique>465)
View(top_unique)
View(pack_sum)
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
swirl()
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res<-gather(students2,sex_class,count,-grade)
res
?seperate
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
submit
submit()
submit()
students3
submit()
?spread
submit()
library(readr)
parse_numeric("class5")
?mutate
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
restore()
reset()
swirl()
reset()
swirl()
submit()
students3
parse_numeric(c("class1", "class5", "class2", "class4", "class3"))
submit()
submit()
submit()
submit()
submit()
View(students4)
View(students3)
View(result3)
View(students3)
View(students4)
View(students3)
?parse_numeric
View(students3)
View(students4)
View(students4)
submit()
View(students4)
rm("studens4")
rm("students4")
submit()
View(students3)
submit()
View(students3)
submit()
View(students4)
play()
nct()
nxt()
swirl()
libray(tidyr)
library(stringr)
library(dplyr)
library(reshape2)
options(stringsAsFactors=FALSE)
#Clear environment
rm(list = ls())
# Start the clock
ptm <- proc.time()
#set working directory!!! CHANGE AS REQUIRED!!!!
setwd("f:/coursera/ucihar/")
#Test and Training directories
testdir<-"./test/"
trainingdir<-"./train/"
#Read input files into Dataframes
xTestDF<-data.frame(fread(paste(testdir,"X_test.txt",sep=""), nrows=2947 ,header=FALSE))
yTestDF<-data.frame(fread(paste(testdir,"y_test.txt",sep=""), nrows=2947,header=FALSE))
sTestDF<-data.frame(fread(paste(testdir,"subject_test.txt",sep=""), nrows=2947 ,header=FALSE))
xTrainingDF<-data.frame(fread(paste(trainingdir,"X_train.txt",sep=""), nrows=7352  ,header=FALSE))
yTrainingDF<-data.frame(fread(paste(trainingdir,"y_train.txt",sep=""), nrows=7352 ,header=FALSE))
sTrainingDF<-data.frame(fread(paste(trainingdir,"subject_train.txt",sep=""), nrows=7352  ,header=FALSE))
featureDF<-data.frame(fread("features.txt", nrows=561,header=FALSE))
activityDF<-data.frame(fread("activity_labels.txt", nrows=6 ,header=FALSE))
# The next three sections will be used to create lookup tables to be used later on in script
#Create a lookup table of subject IDs and a description of Subject Type Training or Testing
trainingDF<-data.frame("subjectID"=unique(sTrainingDF$V1),"Dataset"="Training")
testDF<-data.frame("subjectID"=unique(sTestDF$V1),"Dataset"="Test")
subjectDF<-arrange(rbind(trainingDF,testDF),subjectID)
#Create the tidy lookup table of ID and Descriptions for the activities.
colnames(activityDF)<-c("ID" , "Description")
#Create a lookup table with SEARCH terms for grep functions and correspinging COLUMNS and VALUES.
scvDF<-data.frame(search=c("^t","^f","^a","Acc","Gyro","Body","Gravity","X","Y","Z","Jerk","Mag","mean","Mean","std"),
column=c("Domain","Domain","Domain","Sensor","Sensor","Signal Component","Signal Component","Axis","Axis","Axis","Jerk","Magnitude","Measurement","Measurement","Measurement"),
value=c("Time","Frequency(Hz)","Frequency (Rad/s)","Accelerometer","Gyroscope","Body","Gravity","X","Y","Z",FALSE,FALSE,"Mean","Mean","SD"))
#Subset the featured Dataframe to only include mean and Standard Deviation (SD) values
featureDF<-featureDF[grepl("mean|Mean|std",featureDF$V2),]
#Merge datasets first by columns and then by rows. Subset to only exclude the mean and std variables.
trainingDF<-cbind(sTrainingDF,yTrainingDF,xTrainingDF[,featureDF$V1])
testDF<-cbind(sTestDF,yTestDF,xTestDF[,featureDF$V1])
mergeDF<-rbind(trainingDF,testDF)
#Rename columns
colnames(mergeDF)<-c("subjectID", "Activity",featureDF$V2)
#Attach activity labels
mergeDF$Activity <- activityDF[,2][match(mergeDF$Activity , activityDF[,1])]
#Determine the mean by subjectID and activity
meanDF<-aggregate(x=mergeDF[3:88],by=list("subjectID"=as.factor(mergeDF$subjectID),"Activity"=as.factor(mergeDF$Activity)),FUN="mean")
meanDF<-arrange(meanDF,subjectID,Activity)
#Use Melt function to narrow the number of dataframe columns - (from reshape library )
meltDF<-melt(meanDF,id=1:2,measure=3:88)
#Using the Variable column in Tidy Dataframe, separate into different features.
meltDF[c("Measurement","Domain","Sensor","Signal Component","Axis","Jerk","Magnitude")]<-NA
#Fill the columns using the grep function. scvDF is a lookup table with search strings, values and column names
for (i in 1:15) {
meltDF[,paste(scvDF$column[i])][grep(paste(scvDF$search[i]),meltDF$variable)]=paste(scvDF$value[i])
}
#Reorder columns
meltDF<-meltDF[,c("subjectID","Activity","Signal Component","Sensor","Domain","Axis","Jerk","Magnitude","variable","Measurement","value")]
#Add Set column
meltDF<-merge(meltDF,subjectDF,by.x="subjectID")
meltDF<-meltDF[c(1,12,2:11)]
#Sort the dataframe
meltDF<-arrange(meltDF,subjectID,Activity)
meltDF$variable<-NULL
# Create the tidy Dataframe and format the Activity variable
tidyDF<-meltDF[c(1:7,10:11)]
tidyDF$Activity<-gsub("_"," ",tidyDF$Activity)
tidyDF$Activity<-str_to_title(tidyDF$Activity)
tidyDF$Activity<-gsub(" ","",tidyDF$Activity)
# Stop the clock
proc.time() - ptm
library(stringr)
library(dplyr)
library(reshape2)
library(data.table)
options(stringsAsFactors=FALSE)
#Clear environment
rm(list = ls())
# Start the clock
ptm <- proc.time()
#set working directory!!! CHANGE AS REQUIRED!!!!
setwd("f:/coursera/ucihar/")
#Test and Training directories
testdir<-"./test/"
trainingdir<-"./train/"
#Read input files into Dataframes
xTestDF<-data.frame(fread(paste(testdir,"X_test.txt",sep=""), nrows=2947 ,header=FALSE))
yTestDF<-data.frame(fread(paste(testdir,"y_test.txt",sep=""), nrows=2947,header=FALSE))
sTestDF<-data.frame(fread(paste(testdir,"subject_test.txt",sep=""), nrows=2947 ,header=FALSE))
xTrainingDF<-data.frame(fread(paste(trainingdir,"X_train.txt",sep=""), nrows=7352  ,header=FALSE))
yTrainingDF<-data.frame(fread(paste(trainingdir,"y_train.txt",sep=""), nrows=7352 ,header=FALSE))
sTrainingDF<-data.frame(fread(paste(trainingdir,"subject_train.txt",sep=""), nrows=7352  ,header=FALSE))
featureDF<-data.frame(fread("features.txt", nrows=561,header=FALSE))
activityDF<-data.frame(fread("activity_labels.txt", nrows=6 ,header=FALSE))
# The next three sections will be used to create lookup tables to be used later on in script
#Create a lookup table of subject IDs and a description of Subject Type Training or Testing
trainingDF<-data.frame("subjectID"=unique(sTrainingDF$V1),"Dataset"="Training")
testDF<-data.frame("subjectID"=unique(sTestDF$V1),"Dataset"="Test")
subjectDF<-arrange(rbind(trainingDF,testDF),subjectID)
#Create the tidy lookup table of ID and Descriptions for the activities.
colnames(activityDF)<-c("ID" , "Description")
#Create a lookup table with SEARCH terms for grep functions and correspinging COLUMNS and VALUES.
scvDF<-data.frame(search=c("^t","^f","^a","Acc","Gyro","Body","Gravity","X","Y","Z","Jerk","Mag","mean","Mean","std"),
column=c("Domain","Domain","Domain","Sensor","Sensor","Signal Component","Signal Component","Axis","Axis","Axis","Jerk","Magnitude","Measurement","Measurement","Measurement"),
value=c("Time","Frequency(Hz)","Frequency (Rad/s)","Accelerometer","Gyroscope","Body","Gravity","X","Y","Z",TRUE,TRUE,"Mean","Mean","SD"))
#Subset the featured Dataframe to only include mean and Standard Deviation (SD) values
featureDF<-featureDF[grepl("mean|Mean|std",featureDF$V2),]
#Merge datasets first by columns and then by rows. Subset to only exclude the mean and std variables.
trainingDF<-cbind(sTrainingDF,yTrainingDF,xTrainingDF[,featureDF$V1])
testDF<-cbind(sTestDF,yTestDF,xTestDF[,featureDF$V1])
mergeDF<-rbind(trainingDF,testDF)
#Rename columns
colnames(mergeDF)<-c("subjectID", "Activity",featureDF$V2)
#Attach activity labels
mergeDF$Activity <- activityDF[,2][match(mergeDF$Activity , activityDF[,1])]
#Determine the mean by subjectID and activity
meanDF<-aggregate(x=mergeDF[3:88],by=list("subjectID"=as.factor(mergeDF$subjectID),"Activity"=as.factor(mergeDF$Activity)),FUN="mean")
meanDF<-arrange(meanDF,subjectID,Activity)
#Use Melt function to narrow the number of dataframe columns - (from reshape library )
meltDF<-melt(meanDF,id=1:2,measure=3:88)
#Using the Variable column in Tidy Dataframe, separate into different features and initialise variables with NA.
meltDF[c("Measurement","Domain","Sensor","Signal Component","Axis")]<-NA
meltDF$Jerk<-FALSE
meltDF$Magnitude<-FALSE
#Fill in the actual values of the variables using the grep function. scvDF is a lookup table with search strings, values and column names
for (i in 1:15) {
meltDF[,paste(scvDF$column[i])][grep(paste(scvDF$search[i]),meltDF$variable)]=paste(scvDF$value[i])
}
#Reorder Variables of  the melt dataframe
meltDF<-meltDF[,c("subjectID","Activity","Signal Component","Sensor","Domain","Axis","Jerk","Magnitude","variable","Measurement","value")]
#Add Set column
meltDF<-merge(meltDF,subjectDF,by.x="subjectID")
meltDF<-meltDF[c(1,12,2:11)]
#Sort the dataframe
meltDF<-arrange(meltDF,subjectID,Activity)
meltDF$variable<-NULL
# Create the tidy Dataframe, format the Activity variable and convert variables to factors.
tidyDF<-meltDF#[c(1:11)]
tidyDF$Activity<-gsub("_"," ",tidyDF$Activity)
tidyDF$Activity<-str_to_title(tidyDF$Activity)
tidyDF$Activity<-gsub(" ","",tidyDF$Activity)
tidyDF[,c(1:7,10)]<-lapply(tidyDF[,c(1:7,10)],factor)
#export the tidyDF to csv file
fwrite(tidyDF,"tidyDF.csv")
# Stop the clock
proc.time() - ptm
str(tidyDF)
summary(tidyDF)
getwd
getwd()
setwd(f:/coursera/repos/GettingAndCleaningDataProject)
setwd("f:/coursera/repos/GettingAndCleaningDataProject")
getwd()
